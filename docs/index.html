<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->

<!-- 
  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1"> -->


  <title>PETIT-GAN</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">PETIT-GAN</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/omri-berman/" target="_blank">Omri Berman</a><sup>1,2</sup>,
              </span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/navot-o-9aa646189/" target="_blank">Navot Oz</a><sup>1,2</sup>,
                </span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/davidmendlovic/" target="_blank">David Mendlovic</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/nir-sochen-9879521b/" target="_blank">Nir Sochen</a><sup>1</sup>,
                </span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/yafit-cohen-aa256043/" target="_blank">Yafit Cohen</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/iftach-klapp-06940527/" target="_blank">Iftach Klapp</a><sup>2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <sup>1</sup><span class="author-block">Tel Aviv University</span><br>
                    <sup>2</sup><span class="author-block">Volcani Institute</span><br><br>
                    <a href="https://wacv2024.thecvf.com/">
                    <img src="figs/logos/WACV-Logo_2024.png" alt="Description of the image" id="tree" style="width: 20%;">
                    </a>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">

                    <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/bermanz/PETIT" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>
                
                      <!-- Paper PDF link -->
                      <span class="link-block">
                        <a href="https://openaccess.thecvf.com/content/WACV2024/html/Berman_PETIT-GAN_Physically_Enhanced_Thermal_Image-Translating_Generative_Adversarial_Network_WACV_2024_paper.html" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Poster PDF link -->
                    <span class="link-block">
                      <a href="<LINK-TO-Poster>" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span>

                    <!-- Video link -->
                    <span class="link-block">
                      <a href="https://video.computer.org/Wacv-Posters24/61UsmuyCywwBrlUpxdakl7-wacv24-1891.mp4" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-video"></i>
                      </span>
                      <span>Presentation</span>
                    </a>
                  </span>

                  <!-- Dataset link -->
                  <span class="link-block">
                    <a href="<LINK-TO-DATASET>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="figs/methods/results_comp_ps.png" alt="Description of the image" id="tree" height="100%">
    </img>
      <h2 class="subtitle has-text-centered">
        Our Method Compared to the baseline SOTA methods: (a) Panchromatic (Pan) input. (b) CycleGAN output. (c) CUT output. (d) PETIT output. (e) Real unpaired monochromatic image (Mono) for reference.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser Image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Thermal multispectral imagery is imperative for a plethora of environmental applications.
            Unfortunately, there are no publicly-available datasets of thermal multispectral images with a high spatial resolution that would enable the development of algorithms and systems in this field.
            However, image-to-image (I2I) translation could be used to artificially synthesize such data by transforming largely-available datasets of other visual modalities.
            In most cases, pairs of content-wise-aligned input-target images are not available, making it harder to train and converge to a satisfying solution.
            Nevertheless, some data domains, and particularly the thermal domain, have unique properties that tie the input to the output that could help mitigate those weaknesses.
            We propose PETIT-GAN, a physically enhanced thermal image-translating generative adversarial network to transform between different thermal modalities - a step toward synthesizing a complete thermal multispectral dataset.
            Our novel approach embeds physically modeled prior information in an UI2I translation to produce outputs with greater fidelity to the target modality.
            We further show that our solution outperforms the current state-of-the-art architectures at thermal UI2I translation by approximately 50% with respect to the standard perceptual metrics, and enjoys a more robust training procedure.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Methods -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Methods</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <center><img src="figs/methods/petit.png"
        style="object-fit:fill;
          width:1080px;
          height:540px;
          text-align: center;
          display: inline-block"/>
          </center>
        <h2 class="subtitle has-text-centered">
          Our method combines a calibrated polynomial physical estimator with a deep generator of a generative adversarial network (GAN) to transform 
          a panchromatic (wide-band) thermal image into a content-equivalent monochromatic (narrow-band) thermal image.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <center><img src="figs/methods/cut.png"
        style="object-fit:fill;
          width:1080px;
          height:540px;
          text-align: center;
          display: inline-block"/></center>
        <h2 class="subtitle has-text-centered">          
          Our deep generator's architecture is based on that of <a href="https://junyanz.github.io/CycleGAN/">CycleGAN</a> and 
          <a href="https://taesung.me/ContrastiveUnpairedTranslation/">CUT</a>, two SOTA methods for unpaired image to image (UI2I) translation.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <center><img src="figs/methods/calib_setup.jpg" 
        style="object-fit:fill;
          width:1080px;
          height:540px;
          text-align: center;
          display: inline-block"/></center>
        <h2 class="subtitle has-text-centered">
         To calibrate our physical estimator, we designed an in-house calibration setup: The black body target (d) is observed by the thermal camera (b) through 
         a drilled aperture (c) at the edge of the environmental chamber (a).
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <center><img src="figs/methods/physical_model_tight.png"
      style="object-fit:fill;
        width:540px;
        height:540px;
        text-align: center;
        display: inline-block"/></center>
      <h2 class="subtitle has-text-centered">
        An illustration of a single thermal pixel's model physical coefficient's extraction, using 2-variate polynomial fitting and least-squares minimization criterion.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End Methods -->


<!-- Dataset -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Dataset</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <center><img src="figs/data/light_airplane.jpeg"
        style="object-fit:fill;
          width:720px;
          height:360px;
          text-align: center;
          display: inline-block"/>
          </center>
        <h2 class="subtitle has-text-centered">
          The thermal images for training our model were acquired using a light-weight airplane, 2000 meters above ground level.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <center><img src="figs/data/camera_jig_actual.jpeg"
        style="object-fit:fill;
          width: 200px;
          height:360px;
          text-align: center;
          display: inline-block"/></center>
        <h2 class="subtitle has-text-centered">
          We designed and manufactured a dedicated aerial pod to mount the camera on the airplane's underbelly.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <center><img src="figs/data/sea_land_images.png" 
        style="object-fit:fill;
          width:720px;
          height:360px;
          text-align: center;
          display: inline-block"/></center>
        <h2 class="subtitle has-text-centered">
         A gradient-based classifier was designed to filter out scenes of pure-sea, which are roughly thermally homogenous and not helpful for training.
       </h2>
     </div>
  </div>
</div>
</div>
</section>
<!-- End Dataset -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@InProceedings{Berman_2024_WACV,
  author    = {Berman, Omri and Oz, Navot and Mendlovic, David and Sochen, Nir and Cohen, Yafit and Klapp, Iftach},
  title     = {PETIT-GAN: Physically Enhanced Thermal Image-Translating Generative Adversarial Network},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  month     = {January},
  year      = {2024},
  pages     = {1618-1627}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
